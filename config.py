"""

"""
from paths import *
import torch

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

BY_WORD = False

CHATBOT_INPUTS = CHATBOT_XHJ_INPUT_BY_WORD if BY_WORD else CHATBOT_XHJ_INPUT
CHATBOT_TARGETS = CHATBOT_XHJ_TARGET_BY_WORD if BY_WORD else CHATBOT_XHJ_TARGET

# CHATBOT_INPUTS = CHATBOT_CHATTER_INPUT_BY_WORD if BY_WORD else CHATBOT_CHATTER_INPUT
# CHATBOT_TARGETS = CHATBOT_CHATTER_TARGET_BY_WORD if BY_WORD else CHATBOT_CHATTER_TARGET

# CHATBOT_INPUTS = CHATBOT_WEIBO_INPUT_BY_WORD if BY_WORD else CHATBOT_WEIBO_INPUT
# CHATBOT_TARGETS = CHATBOT_WEIBO_TARGET_BY_WORD if BY_WORD else CHATBOT_WEIBO_TARGET

QA_QUESTIONS = QA_BAIKE_QUESTIONS_BY_WORD if BY_WORD else QA_BAIKE_QUESTIONS
QA_SIM_QUESTIONS = QA_BAIKE_SIM_QUESTIONS_BY_WORD if BY_WORD else QA_BAIKE_SIM_QUESTIONS

# models 模型相关

# WEIBO
# EPOCHES = 8
# BATCH_SIZE = 256
# LEARN_RATE = 0.01
# EMBEDDING_DIM = 200
# XHJ
EPOCHES = 8
BATCH_SIZE = 512
LEARN_RATE = 0.01
EMBEDDING_DIM = 500


MAX_SEQ_LEN = 15 if BY_WORD else 30
TEACHER_FORCING_RATIO = 0.4
BEAM_WIDTH = 3
GRAD_CLIP = 0.1
ATTENTION_FN = 'general'


ENCODER_HIDDEN_SIZE = 128
ENCODER_NUM_LAYERS = 2
ENCODER_DROP_OUT = 0.3

DECODER_HIDDEN_SIZE = ENCODER_HIDDEN_SIZE
DECODER_NUM_LAYERS = 2
DECODER_DROP_OUT = 0.3

# QA SIAMESE
QA_EMBEDDING_DIM = 300
QA_HIDDEN_SIZE = 256
QA_LEARN_RATE = 0.01
QA_BATCH_SIZE = 256
QA_NUM_LAYERS = 2
QA_POOLING_KERNEL = 2
QA_POOLING_STRIDE = 2
